{"cells":[{"cell_type":"markdown","id":"fb4a7085-f6c7-4325-9581-9ea886e9af9c","metadata":{"id":"fb4a7085-f6c7-4325-9581-9ea886e9af9c"},"source":["# Data Processing:"]},{"cell_type":"code","execution_count":2,"id":"Xp7KYjsefUOf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":649,"status":"ok","timestamp":1733877783152,"user":{"displayName":"Loc Nguyen","userId":"14674290205867162983"},"user_tz":360},"id":"Xp7KYjsefUOf","outputId":"86fa5040-351b-4a3a-9d4b-ec0ed3b69efe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Colab Notebooks/Money Printer\n"]}],"source":["# Mount into drive\n","\n","from google.colab import drive\n","\n","drive.mount(\"/content/drive\")\n","\n","%cd '/content/drive/MyDrive/Colab Notebooks/Money Printer/'\n","\n","# !pip install -r requirements.txt\n","# !pip install pandas\n","# !pip install -U scikit-learn\n","# !pip install torchinfo\n"]},{"cell_type":"code","execution_count":77,"id":"6cba238e-466b-4242-becf-e43c0bec9297","metadata":{"id":"6cba238e-466b-4242-becf-e43c0bec9297","executionInfo":{"status":"ok","timestamp":1733880481398,"user_tz":360,"elapsed":93,"user":{"displayName":"Loc Nguyen","userId":"14674290205867162983"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pandas as pd\n","from torch.utils.data import DataLoader, TensorDataset\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from pathlib import Path\n"]},{"cell_type":"markdown","source":["# Data Loader Script"],"metadata":{"id":"vepY47rAOWOj"},"id":"vepY47rAOWOj"},{"cell_type":"code","execution_count":78,"id":"beebdcfb-9863-414e-b809-8a95f4068281","metadata":{"id":"beebdcfb-9863-414e-b809-8a95f4068281","executionInfo":{"status":"ok","timestamp":1733880485061,"user_tz":360,"elapsed":207,"user":{"displayName":"Loc Nguyen","userId":"14674290205867162983"}}},"outputs":[],"source":["def get_data_loaders(device, label=\"label_1\", batch_size=64, use_custom_cols=True, window_size=10, flatten=True):\n","    train_data = pd.read_csv(\"./data/Train_NoAuction_Zscore.csv\")\n","    test_data = pd.read_csv(\"./data/Test_NoAuction_Zscore.csv\")\n","\n","    X_train = train_data.drop(\n","        columns=[\"label_1\", \"label_2\", \"label_3\", \"label_5\", \"label_10\"])\n","    X_test = test_data.drop(\n","        columns=[\"label_1\", \"label_2\", \"label_3\", \"label_5\", \"label_10\"])\n","\n","    y_train = train_data[label] - 1\n","    y_test = test_data[label] - 1\n","    if not use_custom_cols:\n","        X_train = X_train.iloc[:, :40]\n","        X_test = X_test.iloc[:, :40]\n","\n","    X_train = X_train.to_numpy()\n","    X_test = X_test.to_numpy()\n","    y_train = y_train.to_numpy()\n","    y_test = y_test.to_numpy()\n","\n","    # sliding window\n","    if window_size != 1:\n","        D = X_train.shape[1]\n","        X_train = np.lib.stride_tricks.sliding_window_view(\n","            X_train, (window_size, D))\n","        if flatten:\n","          X_train = X_train.reshape((-1, window_size*D))\n","        y_train = y_train[window_size-1:]\n","\n","        X_test = np.lib.stride_tricks.sliding_window_view(\n","            X_test, (window_size, D)).squeeze()\n","        if flatten:\n","            X_test = X_test.reshape((-1, window_size*D))\n","        y_test = y_test[window_size-1:]\n","\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X_train, y_train, shuffle=True, test_size=0.2)\n","\n","    X_train_tensor = torch.tensor(\n","        X_train, dtype=torch.float32).to(device)\n","    X_val_tensor = torch.tensor(\n","        X_val, dtype=torch.float32).to(device)\n","    # Unsqueeze here for DeepLOB and TransLOB models:\n","    X_test_tensor = torch.tensor(\n","        X_test, dtype=torch.float32).unsqueeze(1).to(device)\n","\n","\n","    y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n","    y_val_tensor = torch.tensor(y_val, dtype=torch.long).to(device)\n","    y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n","\n","    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n","    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n","\n","    train_loader = DataLoader(\n","        train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(\n","        val_dataset, batch_size=batch_size, shuffle=False)\n","    test_loader = DataLoader(\n","        test_dataset, batch_size=batch_size, shuffle=False)\n","    return train_loader, val_loader, test_loader"]},{"cell_type":"markdown","source":["# Model Script:"],"metadata":{"id":"XPglQj74Oe3c"},"id":"XPglQj74Oe3c"},{"cell_type":"code","execution_count":79,"id":"b0f31dc1-3578-4d55-8f71-b188ee946d5d","metadata":{"id":"b0f31dc1-3578-4d55-8f71-b188ee946d5d","executionInfo":{"status":"ok","timestamp":1733880485731,"user_tz":360,"elapsed":227,"user":{"displayName":"Loc Nguyen","userId":"14674290205867162983"}}},"outputs":[],"source":["class DeepLOB(nn.Module):\n","    def __init__(self, n_classes=3):\n","        super(DeepLOB, self).__init__()\n","        self.inception_num = 0\n","        self.n_classes = n_classes\n","\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n","            nn.LeakyReLU(negative_slope=0.01),\n","            nn.BatchNorm2d(32),\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n","            nn.LeakyReLU(negative_slope=0.01),\n","            nn.BatchNorm2d(32),\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n","            nn.LeakyReLU(negative_slope=0.01),\n","            nn.BatchNorm2d(32),\n","        )\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n","            nn.Tanh(),\n","            nn.BatchNorm2d(32),\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n","            nn.Tanh(),\n","            nn.BatchNorm2d(32),\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n","            nn.Tanh(),\n","            nn.BatchNorm2d(32),\n","        )\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,10)),\n","            nn.LeakyReLU(negative_slope=0.01),\n","            nn.BatchNorm2d(32),\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n","            nn.LeakyReLU(negative_slope=0.01),\n","            nn.BatchNorm2d(32),\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n","            nn.LeakyReLU(negative_slope=0.01),\n","            nn.BatchNorm2d(32),\n","        )\n","\n","        # 2. Inception Layer:\n","        ##1st inc 1x1 3x1\n","        self.inc1 = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n","            nn.LeakyReLU(negative_slope=0.01),\n","            nn.BatchNorm2d(64),\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,1), padding='same'),\n","            nn.LeakyReLU(negative_slope=0.01),\n","            nn.BatchNorm2d(64),\n","        )\n","        self.inception_num+=1\n","\n","        ##2nd inc 1x1 5x1\n","        self.inc2 = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n","            nn.LeakyReLU(negative_slope=0.01),\n","            nn.BatchNorm2d(64),\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(5,1), padding='same'),\n","            nn.LeakyReLU(negative_slope=0.01),\n","            nn.BatchNorm2d(64),\n","        )\n","        self.inception_num+=1\n","\n","        ##3nd inc max_pool 1x1\n","        self.inc3 = nn.Sequential(\n","            nn.MaxPool2d((3, 1), stride=(1, 1), padding=(1, 0)),\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n","            nn.LeakyReLU(negative_slope=0.01),\n","            nn.BatchNorm2d(64),\n","        )\n","        self.inception_num+=1\n","\n","        # 2. LSTM layers\n","\n","        self.lstm_in_size = self.inception_num*64\n","        self.lstm = nn.LSTM(self.lstm_in_size, hidden_size=64, num_layers=1,batch_first=True)\n","        self.fc1 = nn.Linear(64, self.n_classes)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(1, x.size(0), 64).to(device)\n","        c0 = torch.zeros(1, x.size(0), 64).to(device)\n","\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","\n","        inception1 = self.inc1(x)\n","        inception2 = self.inc2(x)\n","        inception3 = self.inc3(x)\n","\n","        x = torch.cat((inception1, inception2, inception3), dim=1)\n","\n","        x = x.permute(0, 2, 1, 3)\n","        x = torch.reshape(x, (-1, x.shape[1], x.shape[2]))\n","\n","        x, _ = self.lstm(x, (h0, c0))\n","        x = x[:, -1, :]\n","        x = self.fc1(x)\n","        output = torch.softmax(x, dim=1)\n","\n","        return output"]},{"cell_type":"markdown","source":["# Training and Testing Script"],"metadata":{"id":"lKuCCyimOjyq"},"id":"lKuCCyimOjyq"},{"cell_type":"code","execution_count":80,"id":"2cb2b7dc-03e4-4e77-899e-402bb34c00cf","metadata":{"executionInfo":{"elapsed":80,"status":"ok","timestamp":1733880486710,"user":{"displayName":"Loc Nguyen","userId":"14674290205867162983"},"user_tz":360},"id":"2cb2b7dc-03e4-4e77-899e-402bb34c00cf"},"outputs":[],"source":["def test_model(model, test_loader, experiment_name, save=True, display=False):\n","    test_predictions = []\n","    test_labels = []\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for batch, (X, y) in enumerate(test_loader):\n","          pred = model(X)\n","          _, predicted = torch.max(pred, 1)\n","          test_predictions.extend(predicted.cpu().numpy())\n","          test_labels.extend(y.cpu().numpy())\n","    report = classification_report(test_labels, test_predictions)\n","    if display:\n","        print(report)\n","    if save:\n","        with open(f\"results/{experiment_name}/report.txt\", \"w\") as f:\n","            f.write(report)\n","\n","\n","def visualize_curves(train_losses, val_losses, train_accuracies, val_accuracies, experiment_name, save=True, display=False):\n","    plt.plot(np.arange(epochs), train_losses, label=\"train\")\n","    plt.plot(np.arange(epochs), val_losses, label=\"val\")\n","    plt.xlabel(\"epoch\")\n","    plt.ylabel(\"loss\")\n","    plt.title(f\"{experiment_name} loss curves\")\n","    plt.legend()\n","    if display:\n","        plt.show()\n","    if save:\n","        plt.savefig(f\"results/{experiment_name}/loss_curves.png\")\n","    plt.close()\n","\n","    plt.plot(np.arange(epochs), train_accuracies, label=\"train\")\n","    plt.plot(np.arange(epochs), val_accuracies, label=\"val\")\n","    plt.xlabel(\"epoch\")\n","    plt.ylabel(\"accuracy\")\n","    plt.title(f\"{experiment_name} accuracy curves\")\n","    plt.legend()\n","    if display:\n","        plt.show()\n","    if save:\n","        plt.savefig(f\"results/{experiment_name}/accuracy_curves.png\")\n","    plt.close()\n","\n","\n","def train_and_evaluate_model(train_loader, val_loader, test_loader, experiment_name, optimizer, criterion, epochs):\n","    train_losses = []\n","    val_losses = []\n","    train_accuracies = []\n","    val_accuracies = []\n","\n","    for i in range(epochs):\n","        model.train()\n","        running_train_loss = 0\n","        train_correct_predictions = 0\n","        train_total_samples = 0\n","        for batch, (X, y) in enumerate(train_loader):\n","            pred = model(X)\n","            loss = criterion(pred, y)\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            running_train_loss += loss.item()\n","\n","            _, predicted = torch.max(pred, 1)\n","            train_correct_predictions += (predicted == y).sum().item()\n","            train_total_samples += y.size(0)\n","\n","        print(f\"Epoch {i} train loss {running_train_loss/len(train_loader)}\")\n","        train_losses.append(running_train_loss/len(train_loader))\n","\n","        train_accuracy = train_correct_predictions / train_total_samples\n","        train_accuracies.append(train_accuracy)\n","        print(f\"Epoch {i} train accuracy {train_accuracy}\")\n","\n","        val_correct_predictions = 0\n","        val_total_samples = 0\n","        model.eval()\n","        with torch.no_grad():\n","            running_val_loss = 0\n","            for batch, (X, y) in enumerate(val_loader):\n","                pred = model(X)\n","                loss = criterion(pred, y)\n","                running_val_loss += loss.item()\n","\n","                _, predicted = torch.max(pred, 1)\n","                val_correct_predictions += (predicted == y).sum().item()\n","                val_total_samples += y.size(0)\n","\n","            print(f\"Epoch {i} val loss {running_val_loss/len(val_loader)}\")\n","            val_losses.append(running_val_loss/len(val_loader))\n","\n","            val_accuracy = val_correct_predictions / val_total_samples\n","            val_accuracies.append(val_accuracy)\n","            print(f\"Epoch {i} val accuracy {val_accuracy}\")\n","\n","    test_model(model, test_loader, experiment_name)\n","    visualize_curves(train_losses, val_losses,\n","                     train_accuracies, val_accuracies, experiment_name)"]},{"cell_type":"code","source":["# get device\n","device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","print(f\"Using {device} device\")\n","\n","# hyperparameters\n","learning_rate = 1e-4\n","batch_size = 64\n","epochs = 2\n","window_size = 100\n","\n","# model definition\n","# model = MLP(input_size=NUM_FEATURES*window_size, hidden_size=64)\n","model = DeepLOB(n_classes = 3)\n","model = model.to(device)\n","\n","# experiment name\n","experiment_name = \"deeplob-s10\"\n","\n","# loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","for label in [\"label_1\", \"label_2\", \"label_3\", \"label_5\", \"label_10\"]:\n","    new_experiment_name = experiment_name + f\"/{label}\"\n","    Path(\n","        f\"results/{new_experiment_name}\").mkdir(parents=True, exist_ok=True)\n","\n","    # get data loaders\n","    train_loader, val_loader, test_loader = get_data_loaders(device=device, window_size=100, batch_size=64,\n","                                                              flatten=False,use_custom_cols=False)\n","    #unsqueeze test loader for deepLob:\n","    # test_loader = test_loader.unsqueeze(1)\n","\n","    # training and evaluation\n","    train_and_evaluate_model(train_loader, val_loader,\n","                              test_loader, new_experiment_name, optimizer, criterion, epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BD4cJPIcOs1g","outputId":"3db38695-0933-4fa0-e9ff-bbb1d8deb8f6"},"id":"BD4cJPIcOs1g","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n","Epoch 0 train loss 0.9760156907360774\n","Epoch 0 train accuracy 0.5771335464830301\n","Epoch 0 val loss 1.0540281208232045\n","Epoch 0 val accuracy 0.4223533751383253\n","Epoch 1 train loss 0.9456845573451523\n","Epoch 1 train accuracy 0.5966244466305952\n","Epoch 1 val loss 1.1372333243489265\n","Epoch 1 val accuracy 0.2032460346735522\n","Epoch 0 train loss 0.9457831437789153\n","Epoch 0 train accuracy 0.5964707329070339\n","Epoch 0 val loss 1.056595423258841\n","Epoch 0 val accuracy 0.49944669863519\n","Epoch 1 train loss 0.9443229412283083\n","Epoch 1 train accuracy 0.5963785046728972\n","Epoch 1 val loss 0.9713797788135707\n","Epoch 1 val accuracy 0.6000245911717693\n","Epoch 0 train loss 0.946008792092149\n","Epoch 0 train accuracy 0.5962862764387604\n","Epoch 0 val loss 1.021754251793027\n","Epoch 0 val accuracy 0.4436247387187999\n","Epoch 1 train loss 0.9457716514413156\n","Epoch 1 train accuracy 0.5953025086079685\n","Epoch 1 val loss 0.9481913107447326\n","Epoch 1 val accuracy 0.6029755317840895\n","Epoch 0 train loss 0.9432468259732709\n","Epoch 0 train accuracy 0.5973007870142646\n","Epoch 0 val loss 1.0834715338423848\n","Epoch 0 val accuracy 0.533382515676872\n","Epoch 1 train loss 0.9419279955693453\n","Epoch 1 train accuracy 0.5985612395474668\n","Epoch 1 val loss 1.2017685398459435\n","Epoch 1 val accuracy 0.2036149022500922\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0 train loss 0.9410916301028434\n","Epoch 0 train accuracy 0.5997909493359567\n","Epoch 0 val loss 1.0666650994680822\n","Epoch 0 val accuracy 0.5639985245296938\n","Epoch 1 train loss 0.9404144284767346\n","Epoch 1 train accuracy 0.6005287752090507\n","Epoch 1 val loss 0.9758689273148775\n","Epoch 1 val accuracy 0.5719906553547277\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.20"}},"nbformat":4,"nbformat_minor":5}